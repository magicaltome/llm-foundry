max_seq_len: 1024
seed: 1
precision: fp32


models:
-
    model_name: openai/gpt-3.5-turbo
    model:
      name: openai_chat
      version: gpt-3.5-turbo
    tokenizer:
      name: openai
      kwargs:
        name: gpt-3.5-turbo
-
  model_name: openai/davinci
  model:
    name: openai_causal_lm
    version: davinci
  tokenizer:
    name: openai
    kwargs:
      name: davinci


device_eval_batch_size: 4

# FSDP config for model sharding

icl_tasks: 'eval/yamls/lm_tasks.yaml'
model_gauntlet: 'eval/yamls/model_gauntlet.yaml'
