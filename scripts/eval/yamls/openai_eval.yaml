max_seq_len: 1024
seed: 1
precision: fp32


models:
-
  model_name: openai/davinci
  model:
    name: openai
    version: davinci
  tokenizer:
    name: openai
    kwargs:
      name: davinci
-
  model_name: openai/gpt-4
  model:
    name: openai
    version: gpt-4
    chat_model: true
  tokenizer:
    name: openai
    kwargs:
      name: gpt-4
-
  model_name: openai/gpt-3.5-turbo
  model:
    name: openai
    version: gpt-3.5-turbo
    chat_model: true
  tokenizer:
    name: openai
    kwargs:
      name: gpt-3.5-turbo

-
  model_name: openai/text-ada-001
  model:
    name: openai
    version: text-ada-001
  tokenizer:
    name: openai
    kwargs:
      name: text-ada-001
-
model_name: openai/text-babbage-001
model:
  name: openai
  version: text-babbage-001
tokenizer:
  name: openai
  kwargs:
    name: text-babbage-001

device_eval_batch_size: 4

# FSDP config for model sharding

icl_tasks:
-
  label: jeopardy
  dataset_uri: eval/local_data/world_knowledge/jeopardy_small.jsonl # ADD YOUR OWN DATASET URI
  num_fewshot: [10]
  icl_task_type: language_modeling
  continuation_delimiter: "\nAnswer: " # this separates questions from answers
  has_categories: true

model_gauntlet: 'eval/yamls/model_gauntlet.yaml'
